{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawler\n",
    "\n",
    "This code will crawl given websites and save them as files accordingly.\n",
    "This way of saving can be used for pre-processing for the word embedding model in the other code file.\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Samar Hashemi,\n",
    "\n",
    "11045035,\n",
    "\n",
    "Bachelor Artificial Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['https://jobs.ieee.org/jobs/results/keyword/Data+scientist?radius=5&page=1',\n",
    "'https://jobs.ieee.org/jobs/results/keyword/Data+scientist?radius=5&page=2',\n",
    "'https://jobs.ieee.org/jobs/results/keyword/Data+scientist?radius=5&page=3',\n",
    "'https://jobs.ieee.org/jobs/results/keyword/Data+scientist?radius=5&page=4',\n",
    "'https://jobs.ieee.org/jobs/results/keyword/Data+scientist?radius=5&page=5']\n",
    "\n",
    "sauce = urllib.request.urlopen('https://jobs.ieee.org/jobs/results/keyword/Data+scientist?radius=5')\n",
    "\n",
    "soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "# print(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give this function a list of sites and a specific\n",
    "# term that occurs in the links that you are looking for\n",
    "# returns a list of unique vacancies\n",
    "# You can also add a string to the front of the links\n",
    "def crawlsites(websites, searchtag, fronttag):\n",
    "    links = []\n",
    "    for site in websites:\n",
    "        sauce = urllib.request.urlopen(site)\n",
    "        soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "        \n",
    "        body = soup.body\n",
    "        joblinks = []\n",
    "        for url in body.find_all('a'):\n",
    "            joblinks.append(url.get('href'))\n",
    "\n",
    "        \n",
    "        for i in joblinks:\n",
    "            if i != None:\n",
    "                if searchtag in i:\n",
    "                    links.append(fronttag + i)\n",
    "        print(len(links))\n",
    "    uniquejobs = list(set(links))\n",
    "    return(uniquejobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "126\n",
      "190\n",
      "253\n",
      "265\n"
     ]
    }
   ],
   "source": [
    "datasites = crawlsites(sites, 'd?contextType', 'https://jobs.ieee.org')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collects the files and saves them\n",
    "# Altered for IEEE in how to save the file\n",
    "def collectIntel(sites, searchterm):\n",
    "    i = 0\n",
    "    for num in range(len(sites)):\n",
    "        IEEE = open(\"/home/student/ThesisData/Second_IEEE_jobs_{0}.txt\".format(i),\"a\")\n",
    "        sauce = urllib.request.urlopen(sites[i].encode('ascii', 'ignore').decode('ascii'))\n",
    "\n",
    "        soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "        body = soup.body()\n",
    "\n",
    "        title = soup.find('title').find(text=True)\n",
    "        data = soup.find(id=searchterm).get_text()\n",
    "        IEEE.write(str(title))\n",
    "        IEEE.write(str(data))\n",
    "        IEEE.close()\n",
    "        i+= 1\n",
    "        print(num)\n",
    "    \n",
    "# collectIntel(datasites, 'job-posting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=4\n",
    "site = ['https://jobs.ieee.org/jobs/full-stack-s-w-data-analysis-machine-learning-senior-level-Ã¢-eosl-1420-atlanta-ga-98075894-d?contextType=search']\n",
    "IEEE = open(\"/home/student/ThesisData/IEEE_jobs_{0}.txt\".format(i+1),\"a\")\n",
    "sauce = urllib.request.urlopen(site[0].encode('ascii', 'ignore').decode('ascii'))\n",
    "\n",
    "soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "body = soup.body()\n",
    "\n",
    "title = soup.find('title').find(text=True)\n",
    "data = soup.find(id='job-posting').get_text()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetIndeed = [\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=10',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=20',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=30',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=40',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=50',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=60',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=70',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=80',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=90',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=100',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=110',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=120',\n",
    "    'https://www.indeed.nl/jobs?q=data+scientist&l=Utrecht+%28provincie%29&start=130'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "28\n",
      "37\n",
      "44\n",
      "54\n",
      "64\n",
      "74\n",
      "82\n",
      "92\n",
      "102\n",
      "111\n",
      "121\n",
      "131\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "indeedSites = crawlsites(datasetIndeed, 'clk?', 'https://www.indeed.nl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collects the files and saves them\n",
    "# Altered for Indeed in how to save the file\n",
    "def collectIntelIndeed(sites, searchterm):\n",
    "    i = 36\n",
    "    for num in range(36,len(sites)):\n",
    "        IEEE = open(\"/home/student/ThesisData/Indeed_jobs{0}.txt\".format(i),\"a\")\n",
    "        sauce = urllib.request.urlopen(sites[i].encode('ascii', 'ignore').decode('ascii'))\n",
    "\n",
    "        soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "        body = soup.body()\n",
    "\n",
    "        title = soup.find('title').find(text=True)\n",
    "        data = soup.find(id=searchterm).get_text()\n",
    "        IEEE.write(str(title))\n",
    "        IEEE.write(str(data))\n",
    "        IEEE.close()\n",
    "        i+= 1\n",
    "        # So that you can keep track if host kicks you out or disconnect\n",
    "        print(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectIntelIndeed(indeedSites, 'job_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset used for ieee.org\n",
    "dataset2 = [\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=1',\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=2',\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=3',\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=4',\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=5',\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=6',\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=7',\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=8',\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=9',\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=10',\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=11',\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=12',\n",
    "    'https://jobs.ieee.org/jobs/results/keyword/Data+Science?radius=5&page=13'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "126\n",
      "189\n",
      "252\n",
      "315\n",
      "378\n",
      "441\n",
      "504\n",
      "567\n",
      "630\n",
      "693\n",
      "756\n",
      "804\n"
     ]
    }
   ],
   "source": [
    "# Gets all links on ieee sites\n",
    "uniquesites2 = crawlsites(dataset2, 'd?contextType', 'https://jobs.ieee.org')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n"
     ]
    }
   ],
   "source": [
    "# Collects the files and saves them\n",
    "collectIntel(uniquesites2, 'job-posting')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
